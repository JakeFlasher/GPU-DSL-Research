
\documentclass[conference]{IEEEtran}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{fancyvrb}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{url}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\begin{document}

\title{LegalEGraph: Legality-Aware Equality Saturation for Layout and Asynchronous Schedule Co-Optimization on Modern GPUs}

\author{\IEEEauthorblockN{Principal Architect (Research Proposal)}}
\maketitle

\begin{abstract}
Modern NVIDIA GPUs expose performance-critical paths via descriptor-driven, asynchronous data movement and tightly specified synchronization protocols. As a result, many transformations that preserve indexing semantics (``layout equivalence'') or SSA dependencies (``schedule equivalence'') are nevertheless \emph{illegal} (violating TMA tensor-map admissibility or WGMMA descriptor encodability) or \emph{temporally unsafe} (relying on absent ordering guarantees or violating mbarrier tx-count/phase rules), leading to step-function performance cliffs, invalid instruction behavior, or deadlock.
We propose \emph{LegalEGraph}, a legality-aware equality saturation engine that jointly searches the space of tensor layouts and asynchronous pipeline schedules, while enforcing hard hardware legality constraints via e-class analyses. LegalEGraph extracts only legal implementations for a target ISA (e.g., SM90/Hopper) and falls back with precise diagnostics when no legal fast path exists. The prototype targets Triton$\rightarrow$MLIR$\rightarrow$NVGPU$\rightarrow$NVVM/PTX, reusing NVGPU's tokenized async/barrier modeling and emitting host-side tensor-map creation boundaries when required.
\end{abstract}

\section{Introduction \& Motivation}
\subsection{The combinatorial explosion meets binary legality}
On modern GPUs, the compiler problem is no longer: ``find a clever swizzle.'' It is:
\begin{quote}
\emph{(layout equivalences)} $\times$ \emph{(async pipeline schedules)} $\times$ \emph{(hardware legality predicates)}.
\end{quote}

\textbf{Layout equivalences are abundant.} Linear Layouts show that many distinct bit-level mappings can be represented and converted systematically (as $\mathbb{F}_2$ linear maps) and integrated into a production backend (Triton) \cite{zhou2026linear}. ISL relations unify CuTe layouts, swizzles, and Triton linear layouts under a single formalism, enabling composition/inversion/complement reasoning \cite{bhaskaracharya2025isl}. Categorical foundations provide a principled characterization of a large tractable subset of CuTe's layout algebra \cite{carlisle2026categorical}.

\textbf{Schedule equivalences are abundant.} There are many ways to place pipeline stages, form bulk async-groups, or choose wait distances while preserving SSA dependencies.

\textbf{But hardware legality is sparse, discrete, and unforgiving.} Consider four representative cliffs that dominate Hopper-class kernels:

\begin{enumerate}
  \item \textbf{TMA tensor-map admissibility (binary cliff).} A tiled TMA tensor map created via \texttt{cuTensorMapEncodeTiled} must satisfy strict constraints: \texttt{tensorRank}$\le 5$, \texttt{tensorMap} 64B-aligned, \texttt{globalAddress} 16B-aligned (often 32B in some modes), \texttt{globalStrides} multiples of 16 and $<2^{40}$, \texttt{boxDim}$\le 256$, \texttt{elementStrides}$\le 8$, and additional swizzle/interleave coupling and inner-dimension bounds \cite{cuda_driver_tensormap}.
  \item \textbf{WGMMA shared-memory descriptor encodability (quantization cliff).} PTX defines a packed 64-bit matrix descriptor whose byte offsets are quantized by
  \[
    \texttt{matrix-descriptor-encode}(x) = (x \ \&\ 0x3FFFF)\gg 4,
  \]
  and whose swizzle field admits only enumerated values (with invalid bit patterns); additionally, \emph{the descriptor contents must be identical across all warps in a warpgroup} \cite{ptx91}.
  \item \textbf{Bulk async non-ordering (temporal cliff).} PTX explicitly states: \emph{there is no memory ordering guarantee} between any two \texttt{cp.async.bulk.*} operations within the same bulk async-group \cite{ptx91}. A schedule rewrite that assumes intra-group ordering can silently break correctness.
  \item \textbf{mbarrier phase completion with tx-count (deadlock cliff).} PTX defines that an \texttt{mbarrier} phase completes \emph{only when} (i) pending arrivals reach zero \emph{and} (ii) tx-count reaches zero. The \texttt{expect-tx} operation increments tx-count; \texttt{complete-tx} decrements it; mismatches can stall completion indefinitely \cite{ptx91}.
\end{enumerate}

The CUDA Programming Guide further tightens practical constraints for TMA swizzling (e.g., global alignment 128B, shared alignment requirements, and ``instruction is considered invalid'' if the shared-memory inner dimension requirements are violated) \cite{cuda_pg_async}.

\subsection{Why layout equivalence alone is insufficient}
A transformation can preserve a bijection of logical indices but still:
(i) invalidate tensor-map admissibility (e.g., introduce a stride not multiple-of-16), or
(ii) make WGMMA descriptors unencodable (e.g., introduce non-16B-aligned base offsets), or
(iii) change swizzle mode beyond the finite hardware set.

Similarly, a schedule rewrite can preserve SSA dependencies but still:
(i) rely on ordering that PTX does not guarantee inside a bulk async-group, or
(ii) break mbarrier tx-count conservation and prevent phase completion.

\subsection{Proposed solution: LegalEGraph}
\textbf{LegalEGraph} is a compiler engine that:
\begin{itemize}
  \item represents \emph{layout} and \emph{async schedule} choices as \emph{rewriteable terms} in an e-graph;
  \item uses \emph{legality-aware e-class analyses} (in the style of \texttt{egg} \cite{willsey2021egg}) to track and prune candidates that cannot satisfy hardware constraints; and
  \item extracts the best \emph{legal} representative under a cost model, never emitting illegal TMA/WGMMA/mbarrier behavior.
\end{itemize}

\textbf{Integrated modules (not separate directions).}
We incorporate:
(i) \emph{TxGraph-style temporal protocol checking} as a schedule-legality analysis / post-extraction verifier (tx-count conservation, phase discipline), rooted in PTX semantics \cite{ptx91}; and
(ii) a \emph{TMEM legality domain} as an optional extension for Blackwell targets (e.g., \texttt{tcgen05} allocation/lane rules) \cite{ptx91}.

\section{Theoretical Framework (Formalism)}
\subsection{Equality Saturation over Layout and Schedule Terms}
\begin{definition}[Core term language]
We define a typed term language with two interacting fragments: \emph{layout} and \emph{async schedule}.
\smallskip

\noindent\textbf{Layout terms} ($\ell$) describe coordinate-to-address mappings and on-chip staging layouts:
\[
\begin{aligned}
\ell ::=~& \textsf{Base}(S,\textsf{strides}) \mid \textsf{Permute}(\pi,\ell) \mid \textsf{Split}(d,k,\ell) \mid \textsf{Merge}(d_1,d_2,\ell) \\
& \mid \textsf{Pad}(d,p,\ell) \mid \textsf{Reshape}(S',\ell) \mid \textsf{Swizzle}(\mathsf{mode},\ell) \mid \textsf{Cast}(\tau,\ell).
\end{aligned}
\]
These terms are \emph{round-trippable} to (a) Linear Layouts' $\mathbb{F}_2$ matrices when restricted to power-of-two domains \cite{zhou2026linear}, and (b) ISL integer-set relations in the general case \cite{bhaskaracharya2025isl}.
\smallskip

\noindent\textbf{Schedule terms} ($\sigma$) describe explicit asynchronous structure:
\[
\begin{aligned}
\sigma ::=~& \textsf{Seq}(\sigma_1,\sigma_2) \mid \textsf{Stage}(i,\sigma) \mid \textsf{CommitGroup} \mid \textsf{WaitGroup}(k) \\
& \mid \textsf{MBarrierInit}(n) \mid \textsf{ExpectTx}(b) \mid \textsf{Arrive} \mid \textsf{TryWaitParity}(p) \\
& \mid \textsf{AsyncCopy}(\textsf{kind}, b, \ell, \textsf{region}) \mid \textsf{Consume}(\textsf{op},\ell).
\end{aligned}
\]
The key design choice is to make ordering \emph{explicit} via schedule structure and token-like dependencies (mirroring MLIR NVGPU's async token and mbarrier token types) \cite{mlir_nvgpu}.
\end{definition}

\smallskip
\noindent\textbf{Equality saturation.} LegalEGraph uses equality saturation with e-graphs as implemented in \texttt{egg} \cite{willsey2021egg}: we add rewrite rules that preserve semantic equivalence (layout algebraic identities; schedule commutations guarded by dependence checks) until a budget is reached. A key benefit is mitigating phase-ordering problems by exploring many equivalent representations simultaneously.

\subsection{Legality as an E-Class Analysis Lattice}
\begin{definition}[Legality domains and product lattice]
Let an e-graph contain e-classes $E$. We define a \emph{product} analysis
\[
A(e) = A_{\textsc{tma}}(e) \times A_{\textsc{wgmma}}(e) \times A_{\textsc{sched}}(e) \times A_{\textsc{tmem}}(e),
\]
where each component is a finite-height lattice with bottom $\bot$ (infeasible) and top $\top$ (unknown/unchecked). The join operator is componentwise.
\end{definition}

\begin{table}[t]
\caption{Legality analyses tracked inside LegalEGraph (hard constraints, not costs).}
\centering
\begin{tabular}{p{0.20\linewidth} p{0.74\linewidth}}
\toprule
Domain & Key invariants tracked (examples) \\
\midrule
$A_{\textsc{tma}}$ &
TMA tensor-map admissibility: rank $\le 5$, \texttt{tensorMap} 64B alignment, \texttt{globalAddress} alignment, stride modular constraints, $<2^{40}$ stride bound, \texttt{boxDim}$\le 256$, \texttt{elementStrides}$\le 8$, swizzle/interleave coupling, and inner-dimension bounds \cite{cuda_driver_tensormap,cuda_pg_async}. \\
\addlinespace
$A_{\textsc{wgmma}}$ &
WGMMA descriptor encodability: 16B quantization via \texttt{matrix-descriptor-encode} and enumerated swizzle field (invalid values disallowed); warpgroup-uniform descriptors \cite{ptx91}. \\
\addlinespace
$A_{\textsc{sched}}$ &
Temporal safety: (i) no rewrite assumes intra-group ordering for bulk async-groups \cite{ptx91}; (ii) mbarrier protocol obligations, including tx-count conservation and phase completion conditions \cite{ptx91}. \\
\addlinespace
$A_{\textsc{tmem}}$ (optional) &
Blackwell TMEM rules (future extension): allocation constraints and lane partitioning; warp-uniform \texttt{taddr} for collective loads/stores \cite{ptx91}. \\
\bottomrule
\end{tabular}
\end{table}

\begin{definition}[Legality judgment]
For a fully specified extracted kernel term $k$, targeting an ISA feature set $\mathcal{T}$ (e.g., SM90), we define:
\[
\mathsf{Legal}(k;\mathcal{T}) \iff
\mathsf{Legal}_{\textsc{tma}}(k;\mathcal{T}) \wedge
\mathsf{Legal}_{\textsc{wgmma}}(k;\mathcal{T}) \wedge
\mathsf{Legal}_{\textsc{sched}}(k;\mathcal{T})
\wedge
(\mathsf{Legal}_{\textsc{tmem}}(k;\mathcal{T})~\text{if enabled}).
\]
LegalEGraph \emph{never emits} a kernel unless $\mathsf{Legal}(k;\mathcal{T})$ holds under exact checking.
\end{definition}

\noindent\textbf{Key point: analyses are used for pruning and guidance; the guarantee is from extraction+verification.}
E-class analyses are necessarily approximate due to merging; therefore LegalEGraph performs an \emph{exact} legality check on the extracted candidate before codegen, using the most precise available predicate implementation (direct constraint checking against documented bounds for TMA \cite{cuda_driver_tensormap} and PTX-defined encodability/protocol rules \cite{ptx91}).

\subsection{Cost and Extraction under Hard Legality Constraints}
\textbf{Extraction problem.} Given an e-class $e_{\text{root}}$ representing the kernel, find a represented term $k$ such that $\mathsf{Legal}(k;\mathcal{T})$ and $\mathsf{Cost}(k)$ is minimized.

\textbf{Cost model.} We use a multi-objective cost vector with a deterministic lexicographic order:
\[
\mathsf{Cost}(k)=\langle \textsf{Inst}(k),~\textsf{Regs}(k),~\textsf{Pad}(k),~\textsf{BWPred}(k),~\textsf{StallPred}(k)\rangle,
\]
where early components are static proxies (instruction count, register pressure estimate) and later components are analytic predictors (e.g., bytes moved, expected bank conflicts, pipeline depth). We optionally plug in a learned ranking model \emph{after} legality filtering, following the cost-model pattern of Ansor \cite{zheng2020ansor}.

\section{Compiler Architecture (Implementation)}
\begin{figure}[t]
\begin{Verbatim}[fontsize=\scriptsize, commandchars=\\\{\}]
[Input: Triton/CuTe kernel]
        |
  Pass 0: Lower to LegalEGraph IR
        |    - legalegraph.layout
        |    - legalegraph.async_schedule
        v
 [Build E-Graph] --(egg rebuilding)--> [EqSat: bounded rewrites]
        |                                  |
        |                           Pass 2: E-class analyses
        |                                  |-- prune illegal e-classes
        v                                  v
 Pass 3: Extract best legal rep (cost model + exact legality check)
        |
        |----(no legal rep)----> [Fallback plan + diagnostics]
        |
 Pass 4: Lower to NVGPU -> NVVM -> PTX
        |    - host tensor-map creation boundary (cuTensorMapEncodeTiled)
        |    - TMA/mbarrier emission (SM90)
        |    - WGMMA descriptors only if encodable
        v
Pass 5 (optional): TxGraph-style temporal verifier (mbarrier protocol)
        |
      [Output: legal kernel + legality report]
\end{Verbatim}
\caption{LegalEGraph compilation flow.}
\end{figure}

\subsection{IR design in MLIR}
LegalEGraph introduces two MLIR dialects:

\begin{enumerate}
  \item \textbf{\texttt{legalegraph.layout}:} a layout algebra dialect whose ops mirror split/merge/permute/pad/swizzle/reshape, and whose semantics round-trip to:
  (i) Linear Layouts matrices over $\mathbb{F}_2$ for power-of-two domains \cite{zhou2026linear}, and
  (ii) ISL relations for general affine/quasi-affine structure and canonicalization \cite{bhaskaracharya2025isl}.
  The dialect carries \emph{refined attributes/types} summarizing alignment and stride congruences.
  \item \textbf{\texttt{legalegraph.async\_schedule}:} an explicit schedule dialect encoding pipeline stages, bulk async grouping, and mbarrier phases. We model dependencies through SSA tokens compatible with NVGPU's token types (e.g., \texttt{DeviceAsyncTokenType}, \texttt{MBarrierTokenType}) \cite{mlir_nvgpu}.
\end{enumerate}

\noindent\textbf{Lowering boundary to NVGPU.}
After extraction, LegalEGraph lowers to NVGPU ops already modeling:
\begin{itemize}
  \item tensor-map descriptor creation (\texttt{nvgpu.tma.create.descriptor}) which calls CUDA Driver \texttt{cuTensorMapEncodeTiled} \cite{mlir_nvgpu,cuda_driver_tensormap};
  \item TMA async loads/stores with mbarrier completion (\texttt{nvgpu.tma.async.load/store}) \cite{mlir_nvgpu};
  \item mbarrier expect-tx and arrive operations (\texttt{nvgpu.mbarrier.arrive.expect\_tx}) aligned with PTX semantics \cite{mlir_nvgpu,ptx91};
  \item warpgroup matrix descriptor generation and WGMMA ops (\texttt{nvgpu.warpgroup.generate.descriptor}, \texttt{nvgpu.warpgroup.mma}) \cite{mlir_nvgpu,ptx91}.
\end{itemize}

\subsection{Key algorithms}
\begin{algorithm}[t]
\caption{LegalEGraph runner (bounded EqSat with legality-aware analyses)}
\label{alg:legalegraph}
\DontPrintSemicolon
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\Input{Kernel IR $K$; rewrite set $R$; target $\mathcal{T}$ (e.g., SM90/PTX~9.1); budgets $(B_{\text{iters}},B_{\text{nodes}})$}
\Output{Legal lowered kernel or diagnosed fallback}
$k_0 \leftarrow \textsc{LowerToTerms}(K)$\;
$G \leftarrow \textsc{InitEGraph}(k_0)$\;
$\textsc{InitAnalyses}(G)$ \tcp*{initialize $A_{\textsc{tma}},A_{\textsc{wgmma}},A_{\textsc{sched}}$}
\For{$i \leftarrow 1$ \KwTo $B_{\text{iters}}$}{
  \ForEach{$r \in R$}{
    \ForEach{match $m$ of $r.\mathsf{lhs}$ in $G$}{
      \If{$\textsc{Guard}(r,m,A)$}{
        $G \leftarrow \textsc{Apply}(G,r,m)$\;
      }
    }
  }
  $G \leftarrow \textsc{Rebuild}(G)$ \tcp*{\texttt{egg} rebuilding maintains congruence invariants \cite{willsey2021egg}}
  $\textsc{UpdateAnalyses}(G)$ \tcp*{propagate legality lattices; mark $\bot$}
  $\textsc{Prune}(G)$ \tcp*{drop e-classes proven infeasible ($A(e)=\bot$) when safe}
  \If{$|G| > B_{\text{nodes}}$}{
    \textbf{break}\;
  }
}
$k^\star \leftarrow \textsc{ExtractMinCostLegal}(G,\mathcal{T})$ \tcp*{exact legality check at extraction}
\If{$k^\star = \emptyset$}{
  \Return $\textsc{FallbackWithDiagnostics}(G)$\;
}
\If{\textbf{not} $\textsc{ExactLegalCheck}(k^\star;\mathcal{T})$}{
  \Return $\textsc{FallbackWithDiagnostics}(G)$ \tcp*{never emit illegal code}
}
$K' \leftarrow \textsc{LowerToNVGPU\_NVVM\_PTX}(k^\star;\mathcal{T})$\;
$\textsc{OptionalTxGraphVerify}(K')$ \tcp*{mbarrier tx-count/phase protocol check \cite{ptx91}}
\Return $K'$\;
\end{algorithm}

\subsection{Schedule legality: explicit handling of PTX temporal semantics}
LegalEGraph treats temporal semantics as first-class constraints:
\begin{itemize}
  \item \textbf{Bulk async-groups:} any schedule rewrite that would rely on intra-group ordering is disallowed, since PTX provides no ordering guarantee between two \texttt{cp.async.bulk.*} operations within the same group \cite{ptx91}. Rewrites that rearrange grouping are allowed \emph{only} if consumers are guarded by explicit waits/barriers.
  \item \textbf{mbarrier protocol:} the schedule legality analysis enforces (and the post-pass verifier re-checks) that tx-count is correctly managed via \texttt{expect-tx}/\texttt{complete-tx}, and that phase completion is reachable only when both pending arrivals and tx-count reach zero \cite{ptx91}. This is the integrated ``TxGraph'' module.
\end{itemize}

\subsection{Failure modes, fallback, and diagnostics}
LegalEGraph is designed for \emph{hard} correctness guarantees and \emph{actionable} failures.

\paragraph{If no legal TMA descriptor exists.}
Typical rejection reasons include: rank $>5$, stride not multiple-of-16, stride $\ge 2^{40}$, boxDim $>256$, elementStrides $>8$, swizzle/interleave mismatch, or inner-dimension violation \cite{cuda_driver_tensormap,cuda_pg_async}. Fallback: lower to a legal non-TMA path (e.g., vectorized \texttt{ld.global}/\texttt{st.shared} or legacy \texttt{cp.async} when applicable), preserving the extracted schedule structure but weakening obligations.

\paragraph{If WGMMA descriptor encodability fails.}
Reasons include non-16B-aligned offsets (violating descriptor quantization), invalid swizzle encoding values, or non-uniform descriptors across the warpgroup \cite{ptx91}. Fallback: emit a legal MMA variant (e.g., \texttt{mma.sync} or alternative tiling) or adjust layout via padding if available in the e-graph.

\paragraph{If schedule legality fails.}
Examples: tx-count mismatch (deadlock risk), reusing shared-memory tiles before completion, or moving operations across required waits. Fallback: conservative waits (e.g., wait on all pending groups), or a safe synchronous schedule.

\paragraph{Diagnostics.}
We emit a structured ``legality report'' with:
(i) number of candidates pruned,
(ii) top rejection reasons, and
(iii) the earliest illegal obligation site (IR location + required predicate).

\subsection{Target assumptions and version drift}
This proposal targets:
\begin{itemize}
  \item \textbf{Hopper / SM90:} bulk async tensor copies and mbarrier expect-tx are available for \texttt{sm\_90}+, and WGMMA variants are gated by target notes (e.g., \texttt{sm\_90a}) \cite{ptx91}.
  \item \textbf{PTX ISA version:} semantics and constraints are referenced against PTX ISA 9.1 documentation \cite{ptx91}.
\end{itemize}
Because PTX and CUDA evolve (new swizzle modes, new descriptor constraints), LegalEGraph is explicitly \emph{versioned}: legality predicates are parameterized by $(\text{PTX version}, \text{SM target})$, and codegen is gated by detected feature sets.

\section{Evaluation Strategy}
\subsection{Baselines}
We will compare against:
\begin{enumerate}
  \item \textbf{Triton backend without LegalEGraph:} existing layout/schedule heuristics (including Linear Layouts where enabled) \cite{zhou2026linear}.
  \item \textbf{CUTLASS/CuTe:} expert library implementations and TMA utilities \cite{cutlass_cute_tma}.
  \item \textbf{Hand-tuned async pipelines:} FlashAttention-3 style kernels as a representative ``expert schedule'' baseline \cite{shah2024fa3}.
\end{enumerate}

\subsection{Benchmarks}
\begin{itemize}
  \item \textbf{TritonBench} as the primary operator suite and regression harness \cite{tritonbench}.
  \item \textbf{Attention kernels:} forward attention variants inspired by FlashAttention-3 (to stress TMA + asynchrony) \cite{shah2024fa3}.
  \item \textbf{WGMMA-heavy GEMM/MLP kernels:} to stress descriptor encodability and shared-memory layout constraints \cite{ptx91}.
  \item \textbf{Optional ragged attention / variable sequence length:} to stress edge tiles, masking, and tx-count accounting.
\end{itemize}

\subsection{Metrics (beyond speedup)}
We will report, at minimum:
\begin{enumerate}
  \item \textbf{Compile time:} saturation iterations, e-graph nodes/e-classes, rebuild time, analysis time, extraction time.
  \item \textbf{Search behavior:} \#candidates explored; \#pruned by legality; top rejection reasons.
  \item \textbf{Fast-path hit rate:} fraction of kernels/code paths using TMA + WGMMA versus fallback.
  \item \textbf{Runtime:} throughput and latency; achieved bandwidth.
  \item \textbf{Stalls/bubbles:} barrier-related stall indicators and pipeline bubbles via Nsight Compute (conceptually: ``waiting on barrier/async completion'').
  \item \textbf{Code quality:} instruction count and registers/thread (occupancy proxy), plus shared-memory bank-conflict indicators where applicable.
\end{enumerate}

\begin{table}[t]
\caption{Planned measurements and instrumentation points.}
\centering
\begin{tabular}{ll}
\toprule
Metric & Measurement mechanism \\
\midrule
E-graph size / iterations & compiler logs (\texttt{egg}-style runner stats) \cite{willsey2021egg} \\
Candidates pruned / reasons & legality analysis logs (TMA/WGMMA/schedule domains) \\
Fast-path hit rate & codegen classification (TMA vs non-TMA; WGMMA vs fallback) \\
Runtime throughput/latency & TritonBench harness \cite{tritonbench} \\
Bandwidth + stalls & profiler (Nsight Compute) + schedule annotations \\
Regs/thread + code size & backend reports (NVVM/PTXAS) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ablations}
We will isolate contributions via:
\begin{itemize}
  \item \textbf{Legality pruning ON vs OFF:} effect on compile time and quality; ensures we quantify the value of early pruning.
  \item \textbf{ISL canonicalization merging ON vs OFF:} effect on e-graph blow-up, using ISL-based normalization for aggressive merging \cite{bhaskaracharya2025isl}.
  \item \textbf{Schedule rewrites ON vs OFF:} isolate gains from temporal search versus layout-only search.
  \item \textbf{Learned cost model ON vs analytic-only:} following the learned ranking add-on pattern \cite{zheng2020ansor}.
  \item \textbf{TxGraph verifier ON vs OFF:} bug yield and overhead; expected to catch protocol violations tied to mbarrier tx-count semantics \cite{ptx91}.
\end{itemize}

\section{Related Work}
\textbf{Equality saturation and e-graphs.} \texttt{egg} introduced rebuilding and e-class analyses as practical foundations for equality saturation \cite{willsey2021egg}. Tensat applies equality saturation to tensor graph superoptimization \cite{yang2021tensat}. The \texttt{eqsat} MLIR dialect argues for representing e-graphs natively in MLIR \cite{merckx2025eqsat}; LegalEGraph is compatible with this direction and can adopt such an IR to reduce translation overhead.

\textbf{Tensor compilers and tuning systems.} Triton popularized tile-first kernel programming for GPUs \cite{tillet2019triton}. Ansor demonstrates the effectiveness of large schedule spaces plus learned cost models \cite{zheng2020ansor}. MLIR provides the multi-level dialect infrastructure needed to integrate domain-specific IRs and progressive lowering \cite{lattner2020mlir}.

\textbf{Layout formalisms (seed papers).} Linear Layouts provides an effective backend representation for a large family of bit-level layouts and conversions, but is not designed to encode descriptor-driven legality or temporal barrier protocols \cite{zhou2026linear}. ISL relations unify CuTe and linear layouts for formal reasoning, explicitly positioning itself as foundational rather than a performance optimizer \cite{bhaskaracharya2025isl}. Categorical foundations characterize tractable CuTe layouts and provide a semantics-aligned implementation reference, but do not integrate GPU ISA legality constraints \cite{carlisle2026categorical}.

\textbf{GPU ISA semantics and formal models.} PTX ISA specifies the relevant ordering and protocol semantics for bulk async and mbarrier objects \cite{ptx91}. Formal analysis of the PTX memory consistency model provides methodological inspiration for bounded-checking and protocol validation infrastructure \cite{lustig2019ptxmodel}.

\section{Conclusion}
LegalEGraph reframes GPU kernel optimization as \emph{legality-constrained} equality saturation over layout \emph{and} asynchronous schedule spaces. By integrating hard hardware predicates (TMA admissibility, WGMMA descriptor encodability, and PTX temporal protocols) as e-class analyses and enforcing exact legality at extraction, LegalEGraph aims to convert expert-only descriptor/schedule reasoning into a compiler-guaranteed invariant---with measurable benefits in both performance robustness and compiler engineering scalability.

\begin{thebibliography}{25}

\bibitem{ptx91}
NVIDIA Corporation, ``Parallel Thread Execution ISA (PTX ISA) 9.1 Documentation,'' 2025--2026. [Online]. Available: \url{https://docs.nvidia.com/cuda/parallel-thread-execution/index.html}. Accessed: Jan.~2026.

\bibitem{cuda_driver_tensormap}
NVIDIA Corporation, ``CUDA Driver API: Tensor Map Object Management (CUDA Toolkit v13.0.1),'' 2025. [Online]. Available: \url{https://docs.nvidia.com/cuda/archive/13.0.1/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html}. Accessed: Jan.~2026.

\bibitem{cuda_pg_async}
NVIDIA Corporation, ``CUDA C++ Programming Guide: Asynchronous Data Copies (Section 4.11),'' 2024--2026. [Online]. Available: \url{https://docs.nvidia.com/cuda/cuda-programming-guide/04-special-topics/async-copies.html}. Accessed: Jan.~2026.

\bibitem{mlir_nvgpu}
LLVM/MLIR Project, ``MLIR NVGPU Dialect Documentation,'' 2024--2026. [Online]. Available: \url{https://mlir.llvm.org/docs/Dialects/NVGPU/}. Accessed: Jan.~2026.

\bibitem{cutlass_cute_tma}
NVIDIA Corporation, ``CUTLASS/CuTe Documentation: CuTe TMA Tensors,'' 2024--2026. [Online]. Available: \url{https://docs.nvidia.com/cutlass/media/docs/cpp/cute/0z_tma_tensors.html}. Accessed: Jan.~2026.

\bibitem{willsey2021egg}
M.~Willsey, C.~Nandi, Y.~R.~Wang, O.~Flatt, Z.~Tatlock, and P.~Panchekha, ``egg: Fast and Extensible Equality Saturation,'' \emph{Proc. ACM Program. Lang.}, vol.~5, no.~POPL, 2021, doi: 10.1145/3434304. (Preprint: \url{https://arxiv.org/abs/2004.03082})

\bibitem{yang2021tensat}
Y.~Yang, P.~M.~Phothilimthana, Y.~R.~Wang, M.~Willsey, S.~Roy, and J.~Pienaar, ``Equality Saturation for Tensor Graph Superoptimization,'' MLSys 2021. Preprint: \url{https://arxiv.org/abs/2101.01332}.

\bibitem{merckx2025eqsat}
J.~Merckx, A.~Lopoukhine, S.~Coward, J.~Cheng, B.~De~Sutter, and T.~Grosser, ``eqsat: An Equality Saturation Dialect for Non-destructive Rewriting,'' 2025. Preprint: \url{https://arxiv.org/abs/2505.09363}.

\bibitem{zhou2026linear}
K.~Zhou \emph{et al.}, ``Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using $\mathbb{F}_2$,'' in \emph{ASPLOS~'26}, 2026, doi: 10.1145/3760250.3762221. Preprint: \url{https://arxiv.org/html/2505.23819v3}.

\bibitem{bhaskaracharya2025isl}
S.~G.~Bhaskaracharya, A.~Acharya, B.~Hagedorn, and V.~Grover, ``Modeling Layout Abstractions Using Integer Set Relations,'' 2025. Preprint: \url{https://arxiv.org/html/2511.10374v1}.

\bibitem{carlisle2026categorical}
J.~Carlisle, J.~Shah, R.~Stern, and P.~VanKoughnett, ``Categorical Foundations for CuTe Layouts,'' 2026. Preprint: \url{https://arxiv.org/pdf/2601.05972v1}.

\bibitem{shah2024fa3}
J.~Shah, G.~Bikshandi, Y.~Zhang, V.~Thakkar, P.~Ramani, and T.~Dao, ``FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision,'' 2024. Preprint: \url{https://arxiv.org/abs/2407.08608}.

\bibitem{tritonbench}
Meta PyTorch, ``TritonBench: A collection of PyTorch custom operators with example inputs to measure performance,'' GitHub repository. [Online]. Available: \url{https://github.com/meta-pytorch/tritonbench}. Accessed: Jan.~2026.

\bibitem{zheng2020ansor}
L.~Zheng \emph{et al.}, ``Ansor: Generating High-Performance Tensor Programs for Deep Learning,'' in \emph{OSDI~2020}. [Online]. Available: \url{https://www.usenix.org/conference/osdi20/presentation/zheng}. Accessed: Jan.~2026.

\bibitem{lattner2020mlir}
C.~Lattner \emph{et al.}, ``MLIR: A Compiler Infrastructure for the End of Moore's Law,'' 2020. Preprint: \url{https://arxiv.org/abs/2002.11054}.

\bibitem{lustig2019ptxmodel}
D.~Lustig, S.~Sahasrabuddhe, and O.~Giroux, ``A Formal Analysis of the NVIDIA PTX Memory Consistency Model,'' in \emph{ASPLOS}, 2019. [Online]. Available: \url{https://research.nvidia.com/publication/2019-04_formal-analysis-nvidia-ptx-memory-consistency-model}. Accessed: Jan.~2026.

\bibitem{tillet2019triton}
P.~Tillet, H.-T.~Kung, and D.~Cox, ``Triton: An intermediate language and compiler for tiled neural network computations,'' MAPL/PLDI 2019. (Access via IBM Research landing page: \url{https://research.ibm.com/publications/triton-an-intermediate-language-and-compiler-for-tiled-neural-network-computations})

\bibitem{ragan2013halide}
J.~Ragan-Kelley \emph{et al.}, ``Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines,'' in \emph{PLDI}, 2013.

\bibitem{chen2018tvm}
T.~Chen \emph{et al.}, ``TVM: An Automated End-to-End Optimizing Compiler for Deep Learning,'' in \emph{OSDI}, 2018.

\bibitem{jia2019taso}
Z.~Jia \emph{et al.}, ``TASO: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions,'' in \emph{SOSP}, 2019.

\bibitem{baghdadi2019tiramisu}
R.~Baghdadi \emph{et al.}, ``Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code,'' 2018--2019. Preprint: \url{https://arxiv.org/abs/1804.10694}.

\bibitem{willsey2020egg_arxiv}
M.~Willsey \emph{et al.}, ``egg: Fast and Extensible Equality Saturation,'' 2020. Preprint: \url{https://arxiv.org/abs/2004.03082}.

\end{thebibliography}

\end{document}
