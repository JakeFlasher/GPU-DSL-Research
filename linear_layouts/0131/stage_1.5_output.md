Below is a **math-first toolbox** targeted exactly at the **five Stage‑1 expressivity gaps** (descriptor legality, async effects, warpgroup uniformity + fences, `mbarrier` provenance, TMEM resource protocol). I’ve kept each entry **pure-theory–anchored** (algebra / decidable logics / order models), and—per your non‑negotiables—each one maps to:

- **(a) an IR extension**,  
- **(b) an algorithm (decision / construction)**,  
- **(c) a concrete prototype path**,  
and includes **measurable metrics**.

---

## Math Toolbox

| Gap | Proposed_Math_Theory | Source_Field | Mechanism_in_Compiler | Key_Metrics |
|---|---|---|---|---|
| **G1. Descriptor encodability / legality** (TMA `CUtensorMap`: rank bounds, byte alignments, bounded dims/strides, **finite swizzle/interleave enums**) | **Theory A (Algebra): “Affine lattice ∩ rational polyhedron” via SNF/HNF**<br><br>**Why:** legality is “inequalities + congruences + finite-mode disjunction”. Driver constraints like “multiple-of 16/32” are lattice (subgroup) constraints; bounds are polyhedral. ([docs.nvidia.com](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai))<br>**Math object:** decide/synthesize \(x\in\mathbb{Z}^n\) such that \(x\in P\cap (a+\Lambda)\), where \(P\subseteq\mathbb{Q}^n\) (bounds) and \(a+\Lambda\) is an affine lattice (alignments / “multiple-of”). Enums become a finite disjunction over modes. | Integer geometry; commutative algebra (f.g. abelian groups); algorithmic number theory | **IR extension:** introduce `tma.encode` op with symbolic fields (rank, `globalDim`, `globalStrides`, `boxDim`, swizzle/interleave/dtype) and explicit constraint region; result is a *capability value* `tensormap.b1024`.<br>**Algorithm:** (1) split constraints into congruences + inequalities + enums; (2) normalize congruences with **Smith normal form** (basis for solution lattice); (3) intersect with bounds (fixed-dim ILP / Presburger feasibility); (4) enumerate finite swizzle/interleave modes and pick any satisfying witness (or prove UNSAT). (SNF as a canonical algebraic normal form. ([sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S0747717119301312?utm_source=openai)))<br>**Prototype path:** MLIR dialect `gpu.tma` + SNF library + call-out to exact ILP/SMT for the residual inequalities; validate witness by attempting `cuTensorMapEncode*` in compile-time toolchain tests. ([docs.nvidia.com](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai)) | **Soundness:** 0 “declared legal” but rejected by driver encode.<br>**Completeness (practical):** rate of “declared illegal” yet encodable (should → 0).<br>**Compile-time:** solver time per descriptor (ms) + worst-case blowup vs rank.\<br>**Certificate size:** SNF basis + inequality witness. |
| **G1. Descriptor encodability / legality** | **Theory B (Logic/Order): Presburger arithmetic (decidable) + quantifier elimination**<br><br>**Why:** all Stage‑1 legality constraints are definable in FO(\(\mathbb{Z},+\!,<\)) with congruences (since \(x\equiv a \pmod m\) is \(\exists k.\ x=a+mk\)). Newer work improves QE bounds for existential blocks. ([arxiv.org](https://arxiv.org/abs/2405.01183?utm_source=openai))<br>**Math object:** legality predicate \( \exists x.\ \varphi(x)\) where \(\varphi\) is quantifier-free Presburger (inequalities + divisibility encoded by multiplication-free congruences). | Mathematical logic; decidable theories; automata/Presburger complexity | **IR extension:** attach a *first-class Presburger formula* to a `tma.encode` op (or to a `legalize` region).<br>**Algorithm:** choose either (i) QE (Cooper/Ferrante-Rackoff family, or newer singly-exponential one-block QE where applicable), or (ii) satisfiability for the ∃-fragment using small-model bounds / parametric ILP reasoning. ([arxiv.org](https://arxiv.org/abs/2405.01183?utm_source=openai))<br>**Prototype path:** generate SMT-LIB in QF_LIA (or ∃-Presburger) from the IR legality region; discharge with a solver; optionally emit a *witness map* back into IR attributes. (See next row for concrete solver source.) | **Decidability coverage:** % of legality checks fully decided (no timeouts).<br>**QE blowup:** output formula size / input size ratio.<br>**Counterexample quality:** minimal UNSAT core size (if supported) for debugging tiling/layout search. |
| **G1. Descriptor encodability / legality** | **Hybrid: SMT (LIA + BV + finite enums) with proof-producing certificates**<br><br>**Why:** GPU legality is naturally “mixed”: congruences are bit-level; bounds are integer; enums are finite. SMT handles this combination as a *decision engine*, not a heuristic. A practical primary-source solver is **cvc5**. ([link.springer.com](https://link.springer.com/chapter/10.1007/978-3-030-99524-9_24?utm_source=openai))<br>**Math object:** satisfiability in combined theories (QF_LIA ⊗ QF_BV ⊗ finite domains). | Automated reasoning; SMT; decision procedures | **IR extension:** `tma.legalize` pass consumes `tma.encode` with symbolic attrs, produces either (i) concrete descriptor fields, or (ii) compile-time UNSAT with unsat-core annotated to IR nodes.<br>**Algorithm:** DPLL(T)-style SMT; encode “multiple-of 16” as low-bit zeros in BV or as congruence in LIA; model enums as small bitvectors; request model/witness; optionally require proof objects / unsat cores for reproducibility. ([link.springer.com](https://link.springer.com/chapter/10.1007/978-3-030-99524-9_24?utm_source=openai))<br>**Prototype path:** MLIR→SMT-LIB emitter + cvc5 invocation; roundtrip witness into IR; regression tests compare against CUDA driver encoding outcome. ([docs.nvidia.com](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai)) | **Correctness:** mismatch rate vs driver/PTX rules (should be 0). ([docs.nvidia.com](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai))<br>**Performance:** median/worst solver time; #timeouts.<br>**Explainability:** average unsat-core size; % cores mapping cleanly to user-level layout choices (rank, tile, dtype, swizzle). |
| **G2. Async ops + weak memory + completion tokens** (`cp.async.bulk.tensor`, exact byte quanta + weak-memory; completion via barriers) | **Theory A (Algebra): Tropical / max-plus algebra for pipeline schedules**<br><br>**Why:** once correctness is represented as token dependencies, throughput/latency optimization is a classic max-plus linear discrete-event system problem. ([link.springer.com](https://link.springer.com/article/10.1007/s10626-019-00294-w?utm_source=openai))<br>**Math object:** max-plus semiring \((\mathbb{R}\cup\{-\infty\}, \oplus=\max,\ \otimes=+)\); compute earliest-completion times and steady-state cycle time via max-plus linear recurrences / maximum cycle mean. ([link.springer.com](https://link.springer.com/article/10.1007/s10626-019-00294-w?utm_source=openai)) | Discrete-event systems; operations research; idempotent semirings | **IR extension:** every async initiation yields an SSA **event token**; waits consume tokens; group commit/wait become explicit nodes (mirrors PTX `commit_group` / `wait_group`). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** build a timed dependency graph from tokens; encode as max-plus linear system; compute critical cycle mean (throughput bound) and earliest-start schedule; emit an ordering/schedule annotation or transform. ([link.springer.com](https://link.springer.com/article/10.1007/s10626-019-00294-w?utm_source=openai))<br>**Prototype path:** implement `AsyncMaxPlusSchedule` pass that consumes token-IR and produces a pipelined schedule; validate using perf counters (“stalls due to wait_group”) and structural checks. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | **Throughput metric:** predicted initiation interval (II) vs achieved II.<br>**Latency hiding:** % cycles stalled on waits (hardware counters).<br>**Schedule optimality:** gap between computed cycle mean and realized schedule length. |
| **G2. Async ops + weak memory + completion tokens** | **Theory B (Logic/Order): Event-structures / pomsets for weak-memory correctness**<br><br>**Why:** PTX explicitly classifies these ops as **weak memory operations**, so extensional “mapping correctness” is insufficient; we need a partial-order/event semantics that can reason about reordering + release/acquire patterns. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Math object:** (confusion-free) **event structures** with justification / well-justification; or **pomsets with preconditions**. These give compositional semantics for reorderings without admitting “thin-air” behaviors. ([lmcs.episciences.org](https://lmcs.episciences.org/3804?utm_source=openai)) | Concurrency theory; semantics; order theory (partial orders) | **IR extension:** represent async ops as events in an *axiomatic execution graph* (program order + dependency + synchronizes-with edges from barrier release/acquire). PTX gives concrete ordering statements to encode. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** construct per-thread event structure from IR; compute allowed executions (or a conservative abstraction); check a safety property: “every shared read of async-copied region is ordered-after the corresponding completion token (release→acquire path).”<br>**Prototype path:** (1) extract event graph; (2) encode acyclicity/order constraints into SMT; or (3) bounded explicit-state search for litmus-like kernels; emit counterexample trace on violation. (Foundational sources: event-structure model and pomset-with-preconditions model. ([lmcs.episciences.org](https://lmcs.episciences.org/3804?utm_source=openai))) | **Safety:** # proven-safe async regions / total; # counterexamples found.<br>**Model fidelity:** matches PTX-stated weak-memory rules in litmus tests (pass/fail set). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Proof size:** event-graph certificate size; SMT proof/unsat core size. |
| **G2. Async ops + weak memory + completion tokens** | **Hybrid: Timed event structures (correctness) + max-plus (performance)**<br><br>**Why:** separate “is it legal?” (order/consistency) from “is it optimal?” (timing). Both are mathematically clean and compose. | Semantics + idempotent algebra | **IR extension:** single token/event IR supports both passes: (i) `WeakMemCheck` (event-structure constraints), then (ii) `MaxPlusSchedule` (timing).<br>**Algorithm:** prove that the schedule transformation is semantics-preserving under the event-structure model; then compute an optimal (or optimal-under-constraints) pipeline schedule in max-plus.<br>**Prototype path:** two-phase compiler pipeline; regression: (a) litmus-style correctness, (b) throughput counters. ([lmcs.episciences.org](https://lmcs.episciences.org/3804?utm_source=openai)) | **Two-axis KPI:** (1) # UB-free proofs, (2) achieved throughput.<br>**Stability:** schedule invariance under further IR rewrites (idempotence metric). |
| **G3. Warpgroup-uniform control + mandatory fences** (`wgmma.*` requires warpgroup-uniform execution; `wgmma.fence` placement is required else UB) | **Theory A (Algebra): Concurrent Kleene algebra / pomsets-with-boxes to model “collective regions”**<br><br>**Why:** the constraint is intensional: “all lanes execute together” and “fence must occur before/among certain actions.” This is naturally modeled as restricting legal interleavings using algebraic concurrency laws (not heuristic analyses).<br>**Math object:** pomsets + “boxes” (protected sub-pomsets) giving algebraic control over admissible interleavings / interference. ([arxiv.org](https://arxiv.org/abs/1910.14384?utm_source=openai)) | Algebra of programs; true concurrency models | **IR extension:** introduce `wg.region{warpgroup}` blocks whose semantics is “boxed” (collective) and which forbid non-uniform predication; represent `wgmma.fence` as a required algebraic separator operator inside the region. PTX uniformity/fence requirements are the spec constraints. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** equational normalization / refinement checking: prove the IR’s pomset semantics refines the spec pomset (i.e., all behaviors satisfy required fence-before-use and collective execution).<br>**Prototype path:** implement as an *algebraic checker*: translate region to pomset-with-boxes abstraction; check local obligations (fence placement, no conditional divergence) and reject otherwise. ([arxiv.org](https://arxiv.org/abs/1910.14384?utm_source=openai)) | **Proof coverage:** % of `wgmma` sites discharged by algebraic checker (no fallback).<br>**UB risk:** static proof that `.aligned` uniformity holds at each use-site (count). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) |
| **G3. Warpgroup-uniform control + mandatory fences** | **Theory B (Logic/Order): Hyperproperties (HyperLTL) for “uniform predicate” + automata for fence protocol**<br><br>**Why:** uniformity is a *relational* property across threads/traces: \(\forall i,j\in WG.\ p(i)=p(j)\). That’s a hyperproperty, not a trace property. HyperLTL has complete model checking tools. ([arxiv.org](https://arxiv.org/abs/2301.11229?utm_source=openai))<br>**Math object:** HyperLTL specification of warpgroup-uniformity; plus finite-state automaton for mandatory fence patterns (“must appear before first wgmma”, etc.) as a safety property over instruction traces. PTX states the rules precisely. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | Temporal logic; model checking; formal languages | **IR extension:** add explicit `wg.uniform_assume(p)` / `wg.uniform_assert(p)` intrinsics; represent fence obligations as typestate-like automata states attached to the region.<br>**Algorithm:** (1) compile region to a Kripke structure; (2) run HyperLTL model checking for uniformity; (3) run DFA/monitor check for fence protocol derived from PTX rule text. ([arxiv.org](https://arxiv.org/abs/2301.11229?utm_source=openai))<br>**Prototype path:** use an existing HyperLTL engine (AutoHyper) off-line for kernel-sized fragments; embed DFA checking directly in compiler for fence protocol. ([arxiv.org](https://arxiv.org/abs/2301.11229?utm_source=openai)) | **Uniformity discharge rate:** % predicates proved uniform; % requiring code rewrite.<br>**Fence correctness:** 0 missing/extra fence violations vs PTX protocol. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Model-check cost:** states explored; time per region. |
| **G3. Warpgroup-uniform control + mandatory fences** | **Hybrid: Effect types whose effect algebra is (Concurrent) Kleene algebra + HyperLTL fallback** | Algebraic effects + temporal logic | **IR extension:** attach an effect \(E\) to each op; effects compose; `wgmma` requires being in a `Collective(WG)` effect context and a satisfied `FenceState` sub-effect.<br>**Algorithm:** fast effect inference (typechecking) proves most cases; HyperLTL model checking is used only when effect inference can’t prove uniformity (e.g., complex control).<br>**Prototype path:** implement effect inference as a compiler pass; integrate AutoHyper as optional “proof backend” for difficult regions. ([arxiv.org](https://arxiv.org/abs/2301.11229?utm_source=openai)) | **Speed:** % proved by typing alone (fast path).<br>**Fallback frequency:** # HyperLTL checks invoked.<br>**Soundness:** no `.aligned` UB reachable in tested kernels. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) |
| **G4. `mbarrier` object validity + token provenance** (uninitialized barrier UB; `state` must originate from arrive variants) | **Theory A (Algebra): Separation algebras / partial commutative monoids (PCMs) for ownership + token provenance**<br><br>**Why:** barrier validity and token provenance are *resource invariants*. PCMs are the algebra underpinning concurrent separation logics. ([arxiv.org](https://arxiv.org/abs/2010.12686?utm_source=openai))<br>**Math object:** a separation algebra \((R,\circ, \mathbf{0})\) where \(\circ\) is partial disjoint union; barrier objects and their states are resources; `arrive` returns a resource token that must be consumed by waits. PTX’s provenance rule is exactly “token must be in the image of arrive”. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | Algebraic foundations of program logics; concurrency | **IR extension:** `mbarrier.init` produces a linear capability `mb:Barrier`; `mbarrier.arrive` returns `st:BarrierState`; `try_wait/test_wait` require `st` type. Encode `.shared::cta` vs `.shared::cluster` as part of the type. PTX’s rule about uninitialized UB becomes “no operation consumes Barrier unless it exists.” ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** linear/affine typechecking in a PCM model: every use must be justified by ownership; token flow ensures provenance; framing allows local reasoning (no global analysis required if IR is structured). ([arxiv.org](https://arxiv.org/abs/2010.12686?utm_source=openai))<br>**Prototype path:** implement as an IR verifier (like a type-check pass) that rejects invalid `mbarrier` programs; emit a proof sketch as a certificate for each barrier region. | **Safety metric:** 0 `mbarrier` UB sites (proved). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Certificate size:** tokens + framing obligations count.<br>**Modularity:** average region size needed to verify (smaller is better). |
| **G4. `mbarrier` object validity + token provenance** | **Theory B (Logic/Order): Separation logic / hybrid separation logic with typestate (init→live→inval)**<br><br>**Why:** PTX gives an explicit lifecycle (init, use, invalidate) and forbids operations outside the lifecycle; typestate is a logic over a finite automaton of states plus separation. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Math object:** a finite-state automaton of barrier lifecycle + SL assertions over disjoint heaps; tokens are ghost state. Hybrid SL work gives modern, mechanizable formulations. ([link.springer.com](https://link.springer.com/article/10.1007/s10817-025-09739-4?utm_source=openai)) | Program logics; proof theory; state machines (order of phases) | **IR extension:** annotate barrier memory locations with typestate; represent `inval` as transition to “invalid”; disallow reuse without `init` again (matches PTX). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** typestate verification via dataflow + separation; optionally discharge conditions with SMT (e.g., barrier counts/phase constraints).<br>**Prototype path:** implement as (1) compiler pass generating verification conditions, (2) SMT discharge, (3) emit counterexample path if violated. ([link.springer.com](https://link.springer.com/article/10.1007/s10817-025-09739-4?utm_source=openai)) | **Error localization:** shortest counterexample trace length.<br>**False positives:** warnings that cannot happen at runtime (should be low).<br>**Proof automation rate:** % obligations discharged automatically. |
| **G4. `mbarrier` object validity + token provenance** | **Hybrid: PCM-based token types + Presburger side-conditions** | Algebra + decidable arithmetic | **IR extension:** token types ensure provenance; arithmetic constraints (counts, phase bounds) stored as Presburger side-conditions.<br>**Algorithm:** typecheck first (structure), then solve arithmetic with Presburger/SMT. ([arxiv.org](https://arxiv.org/abs/2405.01183?utm_source=openai))<br>**Prototype path:** integrate `BarrierTypeCheck` + `BarrierArithSolve` passes; only arithmetic falls back to solver. | **Layered KPI:** % caught by type layer (cheap) vs arithmetic layer (solver).<br>**Solver load:** average #vars/#constraints per barrier region. |
| **G5. TMEM (Blackwell Tensor Memory) = dynamic allocation + access restrictions + warp-uniform addressing** | **Theory A (Algebra): Dyadic interval algebra / prefix-free code view of power-of-two allocation**<br><br>**Why:** TMEM alloc is “power-of-two columns, unit 32 columns” and must be paired with dealloc—this is exactly the combinatorics of dyadic blocks on a finite line, i.e., a binary-tree algebra (canonical decomposition). PTX states the dyadic constraints. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Math object:** represent allocatable column blocks as **dyadic intervals** over 512 columns (base granularity 32 columns). Disjoint union is partial → a separation algebra; equivalently, a prefix-free set of binary-tree nodes. (Prefix-free code theory gives canonical “no-overlap” conditions; see modern work on prefix-free code optimality as a proxy formal source. ([mdpi.com](https://www.mdpi.com/1999-4893/13/1/12?utm_source=openai))) | Algebraic combinatorics; finite lattices / trees; information-theoretic prefix codes | **IR extension:** `tmem.alloc(k)` returns capability `TMemCap(size=32·2^k)`; `tmem.dealloc(cap)` consumes it; `taddr` formation requires a cap. Encode lane/warp restrictions as refinement types on cap usage. PTX requires dynamic allocation by a warp and deallocation before kernel exit. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** exact tree decision procedure: maintain a binary tree occupancy; allocation is “find a free node at depth k” (decidable, complete); dealloc removes node; fragmentation is computable exactly as a function on the tree (no heuristic).<br>**Prototype path:** implement `TMEMDyadicAllocCheck` pass; instrument kernel to ensure all `tcgen05.alloc` are matched by `tcgen05.dealloc` on all paths. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | **Peak usage:** max allocated columns / 512.<br>**Leak-freedom:** 0 missing dealloc on any CFG path. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Fragmentation:** number of free dyadic blocks at each size (exact distribution). |
| **G5. TMEM dynamic allocation + access restrictions** | **Theory B (Logic/Order): Linear/affine types + hyperproperty check for warp-uniform `taddr`**<br><br>**Why:** PTX imposes collective operand constraints (e.g., `tcgen05.ld` requires all threads in a warp use same `taddr` else UB). That’s both (i) a linear resource property (capability usage) and (ii) a relational/uniformity property across lanes. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | Type theory; relational verification; order properties on CFG paths | **IR extension:** `taddr` is a *refinement* of `TMemCap` plus a “uniform-in-warp” qualifier; loads require this qualifier. PTX’s UB rule becomes a typing rule. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Algorithm:** (1) affine typecheck ensures alloc/dealloc balanced; (2) uniformity check is either (a) symbolic (prove `taddr` lane-invariant) or (b) HyperLTL check on the region computing `taddr`. ([arxiv.org](https://arxiv.org/abs/2301.11229?utm_source=openai))<br>**Prototype path:** implement as verifier pass; emit counterexample showing two lanes with different `taddr` when failing. | **UB elimination:** count of `tcgen05.ld` proven warp-uniform (should be all). ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))<br>**Compile-time:** uniformity proof time per `taddr` region.<br>**CFG robustness:** % of kernels where alloc/dealloc is proven for all exits. |
| **G5. TMEM dynamic allocation + access restrictions** | **Hybrid: Dyadic resource algebra (size) + PCM/SL (lifetime) + HyperLTL (uniform operands)** | Algebra + logic + hyperproperties | **IR extension:** three-layer contract: `TMemCap` (size algebra) + linear ownership (lifetime) + uniformity qualifier (collective operand).<br>**Algorithm:** (1) dyadic feasibility (tree), (2) lifetime proof (PCM/SL), (3) operand-uniform proof (HyperLTL/SMT) only if needed.<br>**Prototype path:** staged verifier pipeline; integrate with `tcgen05.*` lowering. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)) | **Layer attribution:** which % of failures are size vs lifetime vs uniformity.<br>**Proof stability:** re-running after optimization yields same proof obligations count (regression metric). |

---

## Literature Scan (2019–2026, primary/theory‑heavy)

1. **NVIDIA CUDA Driver API — Tensor Map Object Management (`CUtensorMap`)**: encode-time constraints (alignment, bounds, finite swizzle/interleave enums). ([docs.nvidia.com](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai))  
2. **NVIDIA PTX ISA 9.1**: explicit UB cliffs for `wgmma` uniformity + required `wgmma.fence`, weak-memory nature of async copies, exact byte-quanta restrictions for `cp.async.bulk.tensor`, `mbarrier` lifecycle/provenance, and TMEM allocation + warp-uniform `taddr` constraints. ([docs.nvidia.com](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html))  
3. **Haase et al. (2024)**: improved **quantifier elimination** for Presburger arithmetic (existential blocks), giving a sharper theoretical foundation for descriptor legality as a decidable constraint theory. ([arxiv.org](https://arxiv.org/abs/2405.01183?utm_source=openai))  
4. **Benedikt–Chistikov–Mansutti (ICALP 2023)**: complexity bounds for Presburger extensions involving powers of two—relevant because GPU legality frequently encodes dyadic/power‑of‑two structure. ([drops.dagstuhl.de](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ICALP.2023.112?utm_source=openai))  
5. **Barbosa et al. (TACAS 2022)**: **cvc5 SMT solver** (primary tool reference) suitable for QF_LIA/QF_BV-style legality + synthesis checks. ([link.springer.com](https://link.springer.com/chapter/10.1007/978-3-030-99524-9_24?utm_source=openai))  
6. **van den Boom & De Schutter (Discrete Event Dynamic Systems, 2019/2020)**: open-access introduction to **max-plus algebra** for discrete-event systems—directly supports a math-clean async scheduler (max-plus linear models). ([link.springer.com](https://link.springer.com/article/10.1007/s10626-019-00294-w?utm_source=openai))  
7. **Jeffrey & Riely (LMCS 2019)**: event-structure model for **relaxed memory** avoiding thin-air reads while rmitting reorderings—useful as a semantics substrate for PTX weak-memory async effects. ([lmcs.episciences.org](https://lmcs.episciences.org/3804?utm_source=openai))  
8. **Jagadeesan–Jeffrey–Riely (OOPSLA 2020)**: **pomsets with preconditions** as a compositional relaxed-memory model (modern primary semantics source). ([2020.splashcon.org](https://2020.splashcon.org/details/splash-2020-oopsla/70/Pomsets-with-Preconditions-A-Simple-Model-of-Relaxed-Memory?utm_source=openai))  
9. **Brunet & Pym (2019)msets-with-boxes / Concurrent Kleene Algebra extension to control interference (algebraic mechanism for “collective regions”). ([arxiv.org](https://arxiv.org/abs/1910.14384?utm_source=openai))  
10. **Farka et al. (2020) + follow-on JAR 2025**: algebraic foundations for concurrent separation logics via **partial commutative monoids / separation algebras**, directly mapping to barrier/TMEM capability invariants. ([arxiv.org](https://arxiv.org/abs/2010.12686?utm_source=openai))  

---

### If you want Sta (compiler-contract checklist)
I can turn the table into a **minimal “contract language”**: a tiny core IR (types + ops) and *exact* proof obligations for each gap, with (i) decidability boundaries, (ii) certificate formats, and (iii) how to compose proofs across passes.

---
Learn more:
1. [CUDA Driver API :: CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/archive/12.4.0/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html?utm_source=openai)
2. [Computing nearby non-trivial Smith forms - ScienceDi](https://www.sciencedirect.com/science/article/pii/S0747717119301312?utm_source=openai)
3. [An efficient quantifier elimination procedure for Presburger arithmetic](https://arxiv.org/abs/2405.01183?utm_source=openai)
4. [cvc5: A Versatile and Industrial-Strength SMT Solver | Springer Nature Link](https://link.springer.com/chapter/10.1007/978-3-030-99524-9_24?utm_source=openai)
5. [Analysis and control of max-plus linear discrete-event systems: An introduction | Discrete Event Dynamic Systems | Springer Nature Link](https://link.springer.com/article/10.1007/s10626-019-00294-w?utm_source=openai)
6. [1. Introduction — PTX ISA 9.1 documentation](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html)
7. [#5327 - On Thin Air Reads: Towards an Event Structures Model of Relaxed Memory](https://lmcs.episciences.org/3804?utm_source=openai)
8. [Pomsets with Boxes: Protection, Separation, and Locality in Concurrent Kleene Algebra](https://arxiv.org/abs/1910.14384?utm_source=openai)
9. [AutoHyper: Explicit-ate Model Checking for HyperLTL](https://arxiv.org/abs/2301.11229?utm_source=openai)
10. [On Algebraic Abstractions for Concurrent Separation Logics](https://arxiv.org/abs/2010.12686?utm_source=openai)
11. [First-order Hybrid Separation Logic | Journal of Automated Reasoning | Springer Nature Link](https://link.springer.com/article/10.1007/s10817-025-09739-4?utm_source=openai)
12. [Optimal Prefix Free Codes with Partial Sorting](https://www.mdpi.com/1999-4893/13/1/12?utm_source=openai)
13. [The Complexitf Presburger Arithmetic with Power or Powers](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ICALP.2023.112?utm_source=openai)
14. [Pomsets with Preconditions: A Simple Model of Relaxed Memory (SPLASH 2020 - OOPSLA) - SPLASH 2020](https://2020.splashcon.org/details/splash-2020-oopsla/70/Pomsets-with-Preconditions-A-Simple-Model-of-Relaxed-Memory?utm_source=openai)
